{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37aebbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from data.data import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18713bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1bf673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 11034\n",
      "val size 581\n",
      "test size 11615\n"
     ]
    }
   ],
   "source": [
    "data_reader = DataReader(\"data/processed\")\n",
    "data_gen = data_reader.train_batch_generator(1)\n",
    "batch = None\n",
    "x_dist = []\n",
    "y_dist = []\n",
    "\n",
    "for b in data_gen:\n",
    "\n",
    "    x_len = b['x_len']\n",
    "    x = b['x']\n",
    "    \n",
    "    x_dist.extend(x[:, :, 0].squeeze().tolist())\n",
    "    y_dist.extend(x[:, :, 1].squeeze().tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52d6d8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
       "         [ 0.1550,  0.0322,  0.0000],\n",
       "         [ 0.2355,  0.0322,  0.0000],\n",
       "         ...,\n",
       "         [-1.2217, -0.7427,  0.0000],\n",
       "         [-0.7688, -0.3623,  0.0000],\n",
       "         [-0.5414, -0.3120,  1.0000]]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "262c2315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        2.00000e+00, 1.00000e+00, 2.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 1.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 2.00000e+00, 0.00000e+00, 6.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        3.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        2.00000e+00, 1.00000e+00, 2.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 2.00000e+00,\n",
       "        3.00000e+00, 2.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        3.00000e+00, 0.00000e+00, 3.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        3.00000e+00, 3.00000e+00, 2.00000e+00, 2.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00, 3.00000e+00,\n",
       "        3.00000e+00, 0.00000e+00, 2.00000e+00, 5.00000e+00, 3.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 3.00000e+00, 2.00000e+00, 3.00000e+00,\n",
       "        3.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 0.00000e+00, 3.00000e+00, 4.00000e+00, 3.00000e+00,\n",
       "        0.00000e+00, 4.00000e+00, 3.00000e+00, 3.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 1.00000e+00, 1.00000e+00, 3.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00, 1.00000e+00, 4.00000e+00, 1.00000e+00, 3.00000e+00,\n",
       "        4.00000e+00, 6.00000e+00, 3.00000e+00, 5.00000e+00, 4.00000e+00,\n",
       "        0.00000e+00, 4.00000e+00, 1.00000e+00, 5.00000e+00, 0.00000e+00,\n",
       "        1.00000e+00, 4.00000e+00, 2.00000e+00, 4.00000e+00, 6.00000e+00,\n",
       "        4.00000e+00, 2.00000e+00, 3.00000e+00, 2.00000e+00, 6.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 5.00000e+00, 3.00000e+00, 4.00000e+00,\n",
       "        2.00000e+00, 3.00000e+00, 3.00000e+00, 0.00000e+00, 3.00000e+00,\n",
       "        4.00000e+00, 4.00000e+00, 4.00000e+00, 8.00000e+00, 0.00000e+00,\n",
       "        3.00000e+00, 7.00000e+00, 4.00000e+00, 3.00000e+00, 6.00000e+00,\n",
       "        6.00000e+00, 3.00000e+00, 8.00000e+00, 7.00000e+00, 5.00000e+00,\n",
       "        4.00000e+00, 4.00000e+00, 3.00000e+00, 8.00000e+00, 4.00000e+00,\n",
       "        5.00000e+00, 7.00000e+00, 1.00000e+00, 1.00000e+00, 7.00000e+00,\n",
       "        7.00000e+00, 5.00000e+00, 4.00000e+00, 3.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 2.00000e+00, 1.00000e+00, 1.10000e+01, 4.00000e+00,\n",
       "        3.00000e+00, 3.00000e+00, 8.00000e+00, 8.00000e+00, 5.00000e+00,\n",
       "        9.00000e+00, 5.00000e+00, 4.00000e+00, 1.00000e+01, 6.00000e+00,\n",
       "        6.00000e+00, 9.00000e+00, 5.00000e+00, 7.00000e+00, 3.00000e+00,\n",
       "        7.00000e+00, 1.20000e+01, 5.00000e+00, 3.00000e+00, 3.00000e+00,\n",
       "        4.00000e+00, 5.00000e+00, 6.00000e+00, 8.00000e+00, 2.00000e+00,\n",
       "        4.00000e+00, 6.00000e+00, 1.30000e+01, 3.00000e+00, 4.00000e+00,\n",
       "        3.00000e+00, 6.00000e+00, 9.00000e+00, 1.30000e+01, 9.00000e+00,\n",
       "        8.00000e+00, 9.00000e+00, 7.00000e+00, 9.00000e+00, 1.30000e+01,\n",
       "        1.00000e+01, 1.60000e+01, 9.00000e+00, 9.00000e+00, 6.00000e+00,\n",
       "        8.00000e+00, 9.00000e+00, 1.00000e+01, 9.00000e+00, 9.00000e+00,\n",
       "        1.40000e+01, 1.40000e+01, 5.00000e+00, 9.00000e+00, 8.00000e+00,\n",
       "        6.00000e+00, 1.30000e+01, 1.20000e+01, 7.00000e+00, 7.00000e+00,\n",
       "        6.00000e+00, 1.20000e+01, 9.00000e+00, 1.00000e+01, 9.00000e+00,\n",
       "        1.10000e+01, 7.00000e+00, 1.10000e+01, 1.60000e+01, 1.30000e+01,\n",
       "        1.70000e+01, 1.70000e+01, 1.80000e+01, 2.60000e+01, 1.30000e+01,\n",
       "        9.00000e+00, 1.80000e+01, 1.90000e+01, 1.30000e+01, 1.00000e+01,\n",
       "        1.60000e+01, 1.30000e+01, 1.60000e+01, 2.00000e+01, 1.60000e+01,\n",
       "        1.70000e+01, 1.60000e+01, 1.70000e+01, 2.20000e+01, 1.50000e+01,\n",
       "        1.90000e+01, 1.90000e+01, 1.40000e+01, 1.70000e+01, 1.80000e+01,\n",
       "        2.20000e+01, 1.90000e+01, 2.40000e+01, 2.80000e+01, 1.40000e+01,\n",
       "        2.10000e+01, 2.10000e+01, 2.40000e+01, 2.50000e+01, 1.80000e+01,\n",
       "        2.80000e+01, 2.60000e+01, 2.60000e+01, 2.10000e+01, 2.70000e+01,\n",
       "        2.90000e+01, 2.30000e+01, 2.80000e+01, 3.00000e+01, 2.70000e+01,\n",
       "        3.10000e+01, 3.10000e+01, 4.50000e+01, 3.00000e+01, 3.70000e+01,\n",
       "        3.40000e+01, 3.50000e+01, 3.60000e+01, 4.30000e+01, 3.70000e+01,\n",
       "        4.50000e+01, 3.10000e+01, 4.30000e+01, 5.40000e+01, 3.80000e+01,\n",
       "        5.10000e+01, 6.10000e+01, 5.90000e+01, 4.70000e+01, 5.00000e+01,\n",
       "        5.20000e+01, 6.00000e+01, 4.80000e+01, 7.00000e+01, 7.20000e+01,\n",
       "        5.70000e+01, 8.90000e+01, 8.50000e+01, 8.90000e+01, 8.80000e+01,\n",
       "        9.20000e+01, 7.60000e+01, 9.20000e+01, 9.30000e+01, 1.13000e+02,\n",
       "        9.10000e+01, 1.16000e+02, 1.24000e+02, 1.26000e+02, 1.16000e+02,\n",
       "        1.43000e+02, 1.18000e+02, 1.53000e+02, 1.30000e+02, 1.83000e+02,\n",
       "        1.93000e+02, 1.59000e+02, 1.91000e+02, 2.09000e+02, 2.34000e+02,\n",
       "        2.17000e+02, 2.18000e+02, 2.24000e+02, 2.30000e+02, 2.41000e+02,\n",
       "        2.56000e+02, 2.85000e+02, 2.73000e+02, 3.13000e+02, 3.17000e+02,\n",
       "        2.93000e+02, 3.58000e+02, 3.75000e+02, 4.26000e+02, 4.05000e+02,\n",
       "        4.30000e+02, 4.75000e+02, 4.53000e+02, 5.34000e+02, 5.14000e+02,\n",
       "        5.67000e+02, 5.77000e+02, 6.52000e+02, 6.65000e+02, 7.13000e+02,\n",
       "        7.50000e+02, 7.76000e+02, 8.95000e+02, 9.24000e+02, 1.02600e+03,\n",
       "        1.22400e+03, 1.34200e+03, 1.59900e+03, 1.91100e+03, 2.37800e+03,\n",
       "        3.14700e+03, 4.30300e+03, 6.24400e+03, 9.57500e+03, 1.41720e+04,\n",
       "        2.22080e+04, 3.33840e+04, 5.01390e+04, 7.21440e+04, 9.89690e+04,\n",
       "        1.27237e+05, 1.53858e+05, 1.78323e+05, 2.03879e+05, 2.38142e+05,\n",
       "        2.96147e+05, 4.08781e+05, 6.46574e+05, 7.26913e+05, 5.27908e+05,\n",
       "        4.30264e+05, 3.74117e+05, 3.43011e+05, 3.19179e+05, 2.91577e+05,\n",
       "        2.56837e+05, 2.16437e+05, 1.72062e+05, 1.31793e+05, 9.79960e+04,\n",
       "        7.08060e+04, 5.03030e+04, 3.50830e+04, 2.41330e+04, 1.70310e+04,\n",
       "        1.21960e+04, 8.63700e+03, 6.43900e+03, 5.07900e+03, 4.17300e+03,\n",
       "        3.50400e+03, 3.07600e+03, 2.87100e+03, 2.66000e+03, 2.60100e+03,\n",
       "        2.43200e+03, 2.40900e+03, 2.36000e+03, 2.36800e+03, 2.31300e+03,\n",
       "        2.32900e+03, 2.26300e+03, 2.28500e+03, 2.30700e+03, 2.16600e+03,\n",
       "        2.24000e+03, 2.26300e+03, 2.24300e+03, 2.19200e+03, 2.15500e+03,\n",
       "        2.20300e+03, 2.18800e+03, 2.11900e+03, 2.15000e+03, 2.12500e+03,\n",
       "        2.18700e+03, 2.10900e+03, 2.06000e+03, 2.05700e+03, 2.01800e+03,\n",
       "        2.00800e+03, 2.04200e+03, 1.94200e+03, 1.94400e+03, 1.92100e+03,\n",
       "        1.95100e+03, 1.94300e+03, 1.83100e+03, 1.88300e+03, 1.79800e+03,\n",
       "        1.79600e+03, 1.73900e+03, 1.72400e+03, 1.72000e+03, 1.70700e+03,\n",
       "        1.65900e+03, 1.63900e+03, 1.71100e+03, 1.53700e+03, 1.56500e+03,\n",
       "        1.54500e+03, 1.43000e+03, 1.38000e+03, 1.38400e+03, 1.41100e+03,\n",
       "        1.36700e+03, 1.31400e+03, 1.39000e+03, 1.20500e+03, 1.27500e+03,\n",
       "        1.19900e+03, 1.15700e+03, 1.16300e+03, 1.17600e+03, 1.12000e+03,\n",
       "        1.05900e+03, 1.02400e+03, 1.03200e+03, 9.95000e+02, 9.70000e+02,\n",
       "        8.69000e+02, 9.32000e+02, 8.88000e+02, 9.16000e+02, 8.82000e+02,\n",
       "        8.65000e+02, 8.57000e+02, 8.17000e+02, 8.16000e+02, 8.06000e+02,\n",
       "        7.83000e+02, 7.37000e+02, 7.58000e+02, 7.19000e+02, 6.58000e+02,\n",
       "        6.63000e+02, 6.99000e+02, 6.76000e+02, 7.00000e+02, 6.81000e+02,\n",
       "        6.47000e+02, 6.00000e+02, 6.00000e+02, 5.96000e+02, 5.52000e+02,\n",
       "        6.02000e+02, 5.32000e+02, 5.42000e+02, 5.74000e+02, 5.75000e+02,\n",
       "        5.38000e+02, 5.06000e+02, 5.29000e+02, 5.45000e+02, 4.88000e+02,\n",
       "        4.98000e+02, 4.70000e+02, 5.10000e+02, 4.75000e+02, 5.17000e+02,\n",
       "        4.95000e+02, 4.65000e+02, 4.98000e+02, 4.76000e+02, 4.43000e+02,\n",
       "        4.44000e+02, 4.69000e+02, 4.15000e+02, 4.35000e+02, 4.18000e+02,\n",
       "        4.56000e+02, 4.28000e+02, 4.29000e+02, 4.07000e+02, 3.93000e+02,\n",
       "        4.10000e+02, 3.96000e+02, 3.84000e+02, 3.64000e+02, 3.87000e+02,\n",
       "        3.98000e+02, 3.69000e+02, 3.75000e+02, 3.89000e+02, 3.98000e+02,\n",
       "        3.53000e+02, 3.44000e+02, 3.72000e+02, 3.39000e+02, 3.36000e+02,\n",
       "        3.30000e+02, 3.50000e+02, 3.46000e+02, 3.39000e+02, 3.32000e+02,\n",
       "        3.27000e+02, 3.20000e+02, 3.10000e+02, 3.32000e+02, 2.99000e+02,\n",
       "        3.08000e+02, 3.38000e+02, 2.63000e+02, 3.28000e+02, 2.91000e+02,\n",
       "        3.03000e+02, 2.97000e+02, 2.75000e+02, 2.54000e+02, 2.62000e+02,\n",
       "        2.81000e+02, 2.62000e+02, 3.01000e+02, 2.63000e+02, 2.32000e+02,\n",
       "        2.77000e+02, 2.41000e+02, 2.51000e+02, 2.60000e+02, 2.29000e+02,\n",
       "        2.52000e+02, 2.53000e+02, 2.42000e+02, 2.47000e+02, 2.40000e+02,\n",
       "        2.38000e+02, 2.42000e+02, 2.36000e+02, 1.97000e+02, 2.17000e+02,\n",
       "        2.22000e+02, 2.38000e+02, 2.08000e+02, 1.97000e+02, 1.91000e+02,\n",
       "        2.03000e+02, 1.80000e+02, 1.80000e+02, 1.75000e+02, 1.86000e+02,\n",
       "        1.92000e+02, 1.78000e+02, 1.50000e+02, 1.84000e+02, 1.75000e+02,\n",
       "        1.72000e+02, 1.62000e+02, 1.47000e+02, 1.63000e+02, 1.39000e+02,\n",
       "        1.54000e+02, 1.46000e+02, 1.51000e+02, 1.58000e+02, 1.34000e+02,\n",
       "        1.46000e+02, 1.26000e+02, 1.39000e+02, 1.38000e+02, 1.28000e+02,\n",
       "        1.24000e+02, 1.05000e+02, 1.39000e+02, 1.17000e+02, 1.40000e+02,\n",
       "        1.15000e+02, 1.09000e+02, 1.14000e+02, 1.20000e+02, 1.12000e+02,\n",
       "        1.04000e+02, 8.60000e+01, 1.15000e+02, 1.24000e+02, 9.70000e+01,\n",
       "        9.50000e+01, 9.70000e+01, 1.11000e+02, 1.02000e+02, 9.50000e+01,\n",
       "        8.50000e+01, 9.10000e+01, 9.10000e+01, 8.50000e+01, 9.10000e+01,\n",
       "        9.20000e+01, 8.10000e+01, 7.90000e+01, 6.70000e+01, 7.10000e+01,\n",
       "        8.80000e+01, 6.10000e+01, 7.00000e+01, 6.80000e+01, 7.30000e+01,\n",
       "        7.10000e+01, 7.60000e+01, 8.00000e+01, 5.80000e+01, 7.10000e+01,\n",
       "        6.20000e+01, 6.50000e+01, 6.80000e+01, 7.60000e+01, 5.60000e+01,\n",
       "        6.00000e+01, 5.90000e+01, 5.80000e+01, 3.90000e+01, 5.40000e+01,\n",
       "        5.30000e+01, 6.00000e+01, 3.90000e+01, 4.70000e+01, 4.60000e+01,\n",
       "        3.10000e+01, 4.50000e+01, 4.00000e+01, 4.00000e+01, 4.20000e+01,\n",
       "        3.60000e+01, 4.40000e+01, 3.40000e+01, 4.80000e+01, 3.90000e+01,\n",
       "        3.10000e+01, 5.00000e+01, 5.00000e+01, 4.50000e+01, 2.80000e+01,\n",
       "        4.00000e+01, 4.40000e+01, 3.40000e+01, 3.30000e+01, 3.40000e+01,\n",
       "        3.40000e+01, 3.60000e+01, 2.90000e+01, 3.50000e+01, 2.50000e+01,\n",
       "        2.30000e+01, 3.00000e+01, 2.20000e+01, 3.10000e+01, 3.40000e+01,\n",
       "        3.40000e+01, 1.90000e+01, 3.10000e+01, 2.80000e+01, 2.00000e+01,\n",
       "        2.80000e+01, 2.00000e+01, 2.10000e+01, 3.00000e+01, 2.90000e+01,\n",
       "        1.40000e+01, 2.60000e+01, 2.30000e+01, 2.80000e+01, 2.50000e+01,\n",
       "        2.00000e+01, 2.70000e+01, 2.20000e+01, 1.40000e+01, 1.90000e+01,\n",
       "        1.30000e+01, 2.70000e+01, 9.00000e+00, 1.90000e+01, 1.50000e+01,\n",
       "        1.50000e+01, 1.70000e+01, 1.50000e+01, 1.50000e+01, 1.50000e+01,\n",
       "        1.60000e+01, 1.10000e+01, 1.40000e+01, 1.80000e+01, 1.00000e+01,\n",
       "        1.10000e+01, 1.10000e+01, 2.00000e+01, 1.70000e+01, 1.40000e+01,\n",
       "        1.20000e+01, 1.20000e+01, 1.10000e+01, 1.10000e+01, 8.00000e+00,\n",
       "        9.00000e+00, 1.20000e+01, 9.00000e+00, 1.20000e+01, 1.60000e+01,\n",
       "        1.10000e+01, 1.10000e+01, 1.50000e+01, 1.00000e+01, 8.00000e+00,\n",
       "        9.00000e+00, 9.00000e+00, 1.00000e+01, 1.00000e+01, 1.20000e+01,\n",
       "        9.00000e+00, 8.00000e+00, 9.00000e+00, 1.60000e+01, 9.00000e+00,\n",
       "        1.20000e+01, 8.00000e+00, 5.00000e+00, 1.10000e+01, 9.00000e+00,\n",
       "        3.00000e+00, 1.00000e+01, 9.00000e+00, 8.00000e+00, 2.00000e+00,\n",
       "        4.00000e+00, 3.00000e+00, 4.00000e+00, 8.00000e+00, 4.00000e+00,\n",
       "        7.00000e+00, 8.00000e+00, 6.00000e+00, 7.00000e+00, 8.00000e+00,\n",
       "        8.00000e+00, 4.00000e+00, 2.00000e+00, 6.00000e+00, 3.00000e+00,\n",
       "        8.00000e+00, 5.00000e+00, 7.00000e+00, 8.00000e+00, 2.00000e+00,\n",
       "        7.00000e+00, 4.00000e+00, 3.00000e+00, 9.00000e+00, 4.00000e+00,\n",
       "        5.00000e+00, 6.00000e+00, 1.00000e+00, 5.00000e+00, 3.00000e+00,\n",
       "        1.00000e+00, 4.00000e+00, 3.00000e+00, 3.00000e+00, 6.00000e+00,\n",
       "        5.00000e+00, 2.00000e+00, 5.00000e+00, 3.00000e+00, 5.00000e+00,\n",
       "        1.00000e+00, 3.00000e+00, 3.00000e+00, 2.00000e+00, 5.00000e+00,\n",
       "        0.00000e+00, 3.00000e+00, 4.00000e+00, 1.00000e+00, 4.00000e+00,\n",
       "        4.00000e+00, 4.00000e+00, 3.00000e+00, 4.00000e+00, 3.00000e+00,\n",
       "        3.00000e+00, 1.00000e+00, 1.00000e+00, 4.00000e+00, 1.00000e+00,\n",
       "        3.00000e+00, 2.00000e+00, 3.00000e+00, 3.00000e+00, 2.00000e+00,\n",
       "        8.00000e+00, 1.00000e+00, 4.00000e+00, 0.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00, 2.00000e+00, 2.00000e+00, 1.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00, 2.00000e+00, 2.00000e+00, 3.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00, 2.00000e+00, 0.00000e+00, 3.00000e+00, 4.00000e+00,\n",
       "        2.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        2.00000e+00, 4.00000e+00, 2.00000e+00, 0.00000e+00, 1.00000e+00,\n",
       "        0.00000e+00, 2.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00,\n",
       "        3.00000e+00, 1.00000e+00, 2.00000e+00, 0.00000e+00, 2.00000e+00,\n",
       "        2.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([-58.23706436, -58.11893819, -58.00081203, ...,  59.6528506 ,\n",
       "         59.77097677,  59.88910294]),\n",
       " <BarContainer object of 1000 artists>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAWJUlEQVR4nO3df6zddZ3n8edLKkqcxYJ0uqRttmzsaNBdFe5AjbuTUXZKQWP5wyGYydBlG7s7otGMyVicP8jqmODuZhjJahMiHdqNO8gyujQKdrrV2c3+UeTiDxCQ5Q4OSxugdyg/ZpaMBH3vH+eDc7yez72n0J7b2z4fycn5ft/fz/f7+Xw53PM63x/nNFWFJEmjvGqxByBJOn4ZEpKkLkNCktRlSEiSugwJSVLXssUewNF21lln1dq1axd7GJK0pNxzzz1/U1Ur5tZPuJBYu3Yt09PTiz0MSVpSkjw6qu7pJklSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUtGBJJ3pTk+0OP55J8PMmZSfYmebg9n9HaJ8kNSWaS3JvkvKFtbW7tH06yeah+fpL72jo3JEmrj+xDkjQZC4ZEVT1UVW+vqrcD5wPPA18DtgH7qmodsK/NA1wCrGuPrcB2GLzhA9cCFwIXANcOvelvBz40tN7GVu/1IUmagCM93XQR8FdV9SiwCdjZ6juBy9r0JmBXDewHlic5G7gY2FtVh6vqaWAvsLEtO72q9ldVAbvmbGtUH5KkCTjSkLgC+LM2vbKqHm/TTwAr2/Qq4LGhdQ602nz1AyPq8/XxC5JsTTKdZHp2dvYId0mS1DN2SCQ5FXg/8N/mLmtHAHUUx/VL5uujqm6sqqmqmlqx4pf+9T1J0st0JEcSlwDfraon2/yT7VQR7flQqx8E1gytt7rV5quvHlGfrw9J0gQcSUh8kH841QSwG3jpDqXNwO1D9SvbXU7rgWfbKaM9wIYkZ7QL1huAPW3Zc0nWt7uarpyzrVF9SJImYNk4jZK8Dvgt4N8Ola8Dbk2yBXgUuLzV7wAuBWYY3Al1FUBVHU7yGeDu1u7TVXW4TX8YuBk4DbizPebrQ5I0ARmc6j9xTE1N1fT09GIPQ5KWlCT3VNXU3LrfuJYkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkrrGCokky5PcluRHSR5M8s4kZybZm+Th9nxGa5skNySZSXJvkvOGtrO5tX84yeah+vlJ7mvr3JAkrT6yD0nSZIx7JPF54JtV9WbgbcCDwDZgX1WtA/a1eYBLgHXtsRXYDoM3fOBa4ELgAuDaoTf97cCHhtbb2Oq9PiRJE7BgSCR5PfAbwE0AVfVCVT0DbAJ2tmY7gcva9CZgVw3sB5YnORu4GNhbVYer6mlgL7CxLTu9qvZXVQG75mxrVB+SpAkY50jiHGAW+NMk30vypSSvA1ZW1eOtzRPAyja9CnhsaP0DrTZf/cCIOvP08QuSbE0ynWR6dnZ2jF2SJI1jnJBYBpwHbK+qdwD/jzmnfdoRQB394Y3XR1XdWFVTVTW1YsWKYzkMSTqpjBMSB4ADVXVXm7+NQWg82U4V0Z4PteUHgTVD669utfnqq0fUmacPSdIELBgSVfUE8FiSN7XSRcADwG7gpTuUNgO3t+ndwJXtLqf1wLPtlNEeYEOSM9oF6w3AnrbsuSTr211NV87Z1qg+JEkTsGzMdh8FvpzkVOAR4CoGAXNrki3Ao8Dlre0dwKXADPB8a0tVHU7yGeDu1u7TVXW4TX8YuBk4DbizPQCu6/QhSZqADE71nzimpqZqenp6sYchSUtKknuqampu3W9cS5K6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRLSMbZ22zcWewjSy2ZISJK6DAlJUpchIUnqMiQkSV1jhUSSv05yX5LvJ5lutTOT7E3ycHs+o9WT5IYkM0nuTXLe0HY2t/YPJ9k8VD+/bX+mrZv5+pAkTcaRHEm8u6rePvQPZW8D9lXVOmBfmwe4BFjXHluB7TB4wweuBS4ELgCuHXrT3w58aGi9jQv0IUmagFdyumkTsLNN7wQuG6rvqoH9wPIkZwMXA3ur6nBVPQ3sBTa2ZadX1f6qKmDXnG2N6kOSNAHjhkQBf5HkniRbW21lVT3epp8AVrbpVcBjQ+seaLX56gdG1Ofr4xck2ZpkOsn07OzsmLskSVrIsjHb/YuqOpjkV4G9SX40vLCqKkkd/eGN10dV3QjcCDA1NXVMxyFJJ5OxjiSq6mB7PgR8jcE1hSfbqSLa86HW/CCwZmj11a02X331iDrz9CFJmoAFQyLJ65L8o5emgQ3AD4HdwEt3KG0Gbm/Tu4Er211O64Fn2ymjPcCGJGe0C9YbgD1t2XNJ1re7mq6cs61RfUiSJmCc000rga+1u1KXAf+1qr6Z5G7g1iRbgEeBy1v7O4BLgRngeeAqgKo6nOQzwN2t3aer6nCb/jBwM3AacGd7AFzX6UOSNAELhkRVPQK8bUT9KeCiEfUCru5sawewY0R9GnjruH1IkibDb1xLkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldY4dEklOSfC/J19v8OUnuSjKT5CtJTm3117T5mbZ87dA2rmn1h5JcPFTf2GozSbYN1Uf2IS0Va7d9Y7GHIL0iR3Ik8THgwaH5zwHXV9UbgaeBLa2+BXi61a9v7UhyLnAF8BZgI/DFFjynAF8ALgHOBT7Y2s7XhyRpAsYKiSSrgfcCX2rzAd4D3Naa7AQua9Ob2jxt+UWt/Sbglqr6SVX9GJgBLmiPmap6pKpeAG4BNi3QhyRpAsY9kvgT4A+An7X5NwDPVNWLbf4AsKpNrwIeA2jLn23tf16fs06vPl8fvyDJ1iTTSaZnZ2fH3CVJ0kIWDIkk7wMOVdU9ExjPy1JVN1bVVFVNrVixYrGHI0knjGVjtHkX8P4klwKvBU4HPg8sT7KsfdJfDRxs7Q8Ca4ADSZYBrweeGqq/ZHidUfWn5ulDkjQBCx5JVNU1VbW6qtYyuPD8rar6HeDbwAdas83A7W16d5unLf9WVVWrX9HufjoHWAd8B7gbWNfuZDq19bG7rdPrQ5I0Aa/kexKfBH4/yQyD6wc3tfpNwBta/feBbQBVdT9wK/AA8E3g6qr6aTtK+Aiwh8HdU7e2tvP1IUmagHFON/1cVf0l8Jdt+hEGdybNbfP3wG931v8s8NkR9TuAO0bUR/YhSZoMv3EtSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhDQB/jOmWqoMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6FgyJJK9N8p0kP0hyf5J/3+rnJLkryUySryQ5tdVf0+Zn2vK1Q9u6ptUfSnLxUH1jq80k2TZUH9mHJGkyxjmS+Anwnqp6G/B2YGOS9cDngOur6o3A08CW1n4L8HSrX9/akeRc4ArgLcBG4ItJTklyCvAF4BLgXOCDrS3z9CFJmoAFQ6IG/q7Nvro9CngPcFur7wQua9Ob2jxt+UVJ0uq3VNVPqurHwAxwQXvMVNUjVfUCcAuwqa3T60OSNAFjXZNon/i/DxwC9gJ/BTxTVS+2JgeAVW16FfAYQFv+LPCG4fqcdXr1N8zTx9zxbU0ynWR6dnZ2nF2SJI1hrJCoqp9W1duB1Qw++b/5WA7qSFXVjVU1VVVTK1asWOzhSNIJ44jubqqqZ4BvA+8ElidZ1hatBg626YPAGoC2/PXAU8P1Oev06k/N04ckaQLGubtpRZLlbfo04LeABxmExQdas83A7W16d5unLf9WVVWrX9HufjoHWAd8B7gbWNfuZDqVwcXt3W2dXh+SpAlYtnATzgZ2truQXgXcWlVfT/IAcEuSPwK+B9zU2t8E/JckM8BhBm/6VNX9SW4FHgBeBK6uqp8CJPkIsAc4BdhRVfe3bX2y04ckaQIWDImquhd4x4j6IwyuT8yt/z3w251tfRb47Ij6HcAd4/YhSZoMv3EtSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlpQtZu+8ZiD0E6YoaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktS1YEgkWZPk20keSHJ/ko+1+plJ9iZ5uD2f0epJckOSmST3JjlvaFubW/uHk2weqp+f5L62zg1JMl8fkqTJGOdI4kXgE1V1LrAeuDrJucA2YF9VrQP2tXmAS4B17bEV2A6DN3zgWuBC4ALg2qE3/e3Ah4bW29jqvT4kSROwYEhU1eNV9d02/bfAg8AqYBOwszXbCVzWpjcBu2pgP7A8ydnAxcDeqjpcVU8De4GNbdnpVbW/qgrYNWdbo/qQJE3AEV2TSLIWeAdwF7Cyqh5vi54AVrbpVcBjQ6sdaLX56gdG1Jmnj7nj2ppkOsn07OzskeySJGkeY4dEkl8B/hz4eFU9N7ysHQHUUR7bL5ivj6q6saqmqmpqxYoVx3IYknRSGSskkryaQUB8uaq+2spPtlNFtOdDrX4QWDO0+upWm6++ekR9vj4kSRMwzt1NAW4CHqyqPx5atBt46Q6lzcDtQ/Ur211O64Fn2ymjPcCGJGe0C9YbgD1t2XNJ1re+rpyzrVF9SJImYNkYbd4F/C5wX5Lvt9qngOuAW5NsAR4FLm/L7gAuBWaA54GrAKrqcJLPAHe3dp+uqsNt+sPAzcBpwJ3twTx9SJImYMGQqKr/DaSz+KIR7Qu4urOtHcCOEfVp4K0j6k+N6kOSNBl+41o6RtZu+8ZiD0F6xQwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqWjAkkuxIcijJD4dqZybZm+Th9nxGqyfJDUlmktyb5LyhdTa39g8n2TxUPz/JfW2dG5Jkvj4kSZMzzpHEzcDGObVtwL6qWgfsa/MAlwDr2mMrsB0Gb/jAtcCFwAXAtUNv+tuBDw2tt3GBPiRJE7JgSFTV/wIOzylvAna26Z3AZUP1XTWwH1ie5GzgYmBvVR2uqqeBvcDGtuz0qtpfVQXsmrOtUX1Ikibk5V6TWFlVj7fpJ4CVbXoV8NhQuwOtNl/9wIj6fH38kiRbk0wnmZ6dnX0ZuyNJGuUVX7huRwB1FMbysvuoqhuraqqqplasWHEshyKNZe22bxxRXTpevdyQeLKdKqI9H2r1g8CaoXarW22++uoR9fn6kCRNyMsNid3AS3cobQZuH6pf2e5yWg88204Z7QE2JDmjXbDeAOxpy55Lsr7d1XTlnG2N6kOSNCHLFmqQ5M+A3wTOSnKAwV1K1wG3JtkCPApc3prfAVwKzADPA1cBVNXhJJ8B7m7tPl1VL10M/zCDO6hOA+5sD+bpQ5I0IQuGRFV9sLPoohFtC7i6s50dwI4R9WngrSPqT43qQ5I0OX7jWpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhHSULfSvz/mv02kpMSQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiLwDuctFQc9yGRZGOSh5LMJNm22OORpJPJcR0SSU4BvgBcApwLfDDJuYs7KqnPIwSdaJYt9gAWcAEwU1WPACS5BdgEPLCoo5LmeDnhcCwC5a+ve+9R36ZObsd7SKwCHhuaPwBcOLdRkq3A1jb7d0keGnP7ZwF/84pGePw4kfYFTqz9mdi+5HOT6MXX5jj2Svbnn4wqHu8hMZaquhG48UjXSzJdVVPHYEgTdyLtC5xY+3Mi7QucWPtzIu0LHJv9Oa6vSQAHgTVD86tbTZI0Acd7SNwNrEtyTpJTgSuA3Ys8Jkk6aRzXp5uq6sUkHwH2AKcAO6rq/qPYxRGfojqOnUj7AifW/pxI+wIn1v6cSPsCx2B/UlVHe5uSpBPE8X66SZK0iAwJSVLXSRkSST6a5EdJ7k/yH4bq17Sf/3goycWLOcYjleQTSSrJWW0+SW5o+3NvkvMWe4wLSfIf2+tyb5KvJVk+tGxJvjZL+WdlkqxJ8u0kD7S/lY+1+plJ9iZ5uD2fsdhjHVeSU5J8L8nX2/w5Se5qr89X2g0yS0KS5Ulua38zDyZ557F4bU66kEjybgbf2n5bVb0F+E+tfi6Du6feAmwEvth+FuS4l2QNsAH4v0PlS4B17bEV2L4IQztSe4G3VtU/B/4PcA0s3dfmBPhZmReBT1TVucB64Oo2/m3AvqpaB+xr80vFx4AHh+Y/B1xfVW8Enga2LMqoXp7PA9+sqjcDb2OwX0f9tTnpQgL4PeC6qvoJQFUdavVNwC1V9ZOq+jEww+BnQZaC64E/AIbvQtgE7KqB/cDyJGcvyujGVFV/UVUvttn9DL4XA0v3tfn5z8pU1QvASz8rsyRU1eNV9d02/bcM3oRWMdiHna3ZTuCyRRngEUqyGngv8KU2H+A9wG2tyVLal9cDvwHcBFBVL1TVMxyD1+ZkDIlfA/5lO8T8n0l+vdVH/QTIqomP7ggl2QQcrKofzFm0JPdnyL8B7mzTS3Vfluq4f0mStcA7gLuAlVX1eFv0BLByscZ1hP6EwYepn7X5NwDPDH0wWUqvzznALPCn7fTZl5K8jmPw2hzX35N4uZL8D+Afj1j0hwz2+UwGh8+/Dtya5J9OcHhHbIH9+RSDU01Lwnz7UlW3tzZ/yOBUx5cnOTaNluRXgD8HPl5Vzw0+gA9UVSU57u+jT/I+4FBV3ZPkNxd5OEfDMuA84KNVdVeSzzPn1NLRem1OyJCoqn/VW5bk94Cv1uALIt9J8jMGP4p13P4ESG9/kvwzBp8oftD+cFcD301yAcfp/sz32gAk+dfA+4CL6h++xHNc7ssYluq4fy7JqxkExJer6qut/GSSs6vq8XYK81B/C8eNdwHvT3Ip8FrgdAbn9JcnWdaOJpbS63MAOFBVd7X52xiExFF/bU7G003/HXg3QJJfA05l8KuJu4ErkrwmyTkMLvh+Z7EGOY6quq+qfrWq1lbVWgb/45xXVU8w2J8r211O64Fnhw5Dj0tJNjI4HfD+qnp+aNGSe22aJf2zMu2c/U3Ag1X1x0OLdgOb2/Rm4PZJj+1IVdU1VbW6/Z1cAXyrqn4H+DbwgdZsSewLQPsbfyzJm1rpIgb/hMJRf21OyCOJBewAdiT5IfACsLl9Yr0/ya0M/kO/CFxdVT9dxHG+UncAlzK4yPs8cNXiDmcs/xl4DbC3HRntr6p/V1VL8rWZwM/KHGvvAn4XuC/J91vtU8B1DE7TbgEeBS5fnOEdFZ8EbknyR8D3aBeCl4iPAl9uH0AeYfA3/iqO8mvjz3JIkrpOxtNNkqQxGRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXf8fQaelDJLwDgEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_dist, bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fb0550c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-58.237064361572266 59.889102935791016\n",
      "-32.30843734741211 45.285789489746094\n"
     ]
    }
   ],
   "source": [
    "print(min(x_dist), max(x_dist))\n",
    "print(min(y_dist), max(y_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae6fd2ae-0311-4a44-8907-2096547f3d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11615, 1200, 3])\n"
     ]
    }
   ],
   "source": [
    "data_cols = ['x', 'x_len', 'c', 'c_len', 'w_id']\n",
    "data_dir = \"data/processed\"\n",
    "data = []\n",
    "\n",
    "for col in data_cols:\n",
    "    data.append(\n",
    "        torch.from_numpy(\n",
    "            np.load(os.path.join(data_dir, '{}.npy'.format(col)))\n",
    "        )\n",
    "    )\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c3152c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11615, 1200, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110cf467-d105-4e6e-87fa-a51849e8f59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHABET = [\n",
    "    '\\x00', ' ', '!', '\"', '#', \"'\", '(', ')', ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';',\n",
    "    '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "    'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "    'y', 'z'\n",
    "]\n",
    "len(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122becdc-9755-4c60-8323-4720a32122c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = torch.randn(2)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e6360e-cb36-48ea-b545-18ae6934f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 56\n",
      "val size 3\n",
      "test size 59\n"
     ]
    }
   ],
   "source": [
    "DR = WriterDataReader(\"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54536ea7-23dc-4495-b0ba-17c28106b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.0096, -0.1607,  0.0000],\n",
      "         [-0.0336, -0.3333,  0.0000],\n",
      "         ...,\n",
      "         [ 0.1535, -0.1487,  0.0000],\n",
      "         [ 0.0959,  0.2974,  0.0000],\n",
      "         [ 0.0168,  0.4556,  1.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.1593,  0.0774,  0.0000],\n",
      "         [-0.2456,  0.0752,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gen = DR.train_batch_generator(2)\n",
    "for d in gen:\n",
    "    print(d['x'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd6f352-0986-493f-8276-aa645a2c03b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 11034\n",
      "val size 581\n",
      "test size 11615\n",
      "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.0902, -0.0391,  0.0000],\n",
      "         [-0.0090, -0.0661,  0.0000],\n",
      "         ...,\n",
      "         [ 1.0788,  0.6641,  0.0000],\n",
      "         [ 0.8865,  0.3937,  0.0000],\n",
      "         [ 0.5770,  0.1533,  1.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.1063,  0.0792,  0.0000],\n",
      "         [-0.0667,  0.1001,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "D = DataReader(\"processed\")\n",
    "for d in D.train_batch_generator(2):\n",
    "    print(d['x'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f20553-7eb5-4da6-9621-de6b17103ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "alphabet = [\n",
    "    '\\x00', ' ', '!', '\"', '#', \"'\", '(', ')', ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';',\n",
    "    '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "    'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "    'y', 'z'\n",
    "]\n",
    "alphabet_ord = list(map(ord, alphabet))\n",
    "alpha_to_num = defaultdict(int, list(map(reversed, enumerate(alphabet))))\n",
    "num_to_alpha = dict(enumerate(alphabet_ord))\n",
    "\n",
    "MAX_STROKE_LEN = 1200\n",
    "MAX_CHAR_LEN = 75\n",
    "\n",
    "\n",
    "def align(coords):\n",
    "    \"\"\"\n",
    "    corrects for global slant/offset in handwriting strokes\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    X, Y = coords[:, 0].reshape(-1, 1), coords[:, 1].reshape(-1, 1)\n",
    "    X = np.concatenate([np.ones([X.shape[0], 1]), X], axis=1)\n",
    "    offset, slope = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y).squeeze()\n",
    "    theta = np.arctan(slope)\n",
    "    rotation_matrix = np.array(\n",
    "        [[np.cos(theta), -np.sin(theta)],\n",
    "         [np.sin(theta), np.cos(theta)]]\n",
    "    )\n",
    "    coords[:, :2] = np.dot(coords[:, :2], rotation_matrix) - offset\n",
    "    return coords\n",
    "\n",
    "\n",
    "def skew(coords, degrees):\n",
    "    \"\"\"\n",
    "    skews strokes by given degrees\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    theta = degrees * np.pi/180\n",
    "    A = np.array([[np.cos(-theta), 0], [np.sin(-theta), 1]])\n",
    "    coords[:, :2] = np.dot(coords[:, :2], A)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def stretch(coords, x_factor, y_factor):\n",
    "    \"\"\"\n",
    "    stretches strokes along x and y axis\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    coords[:, :2] *= np.array([x_factor, y_factor])\n",
    "    return coords\n",
    "\n",
    "\n",
    "def add_noise(coords, scale):\n",
    "    \"\"\"\n",
    "    adds gaussian noise to strokes\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    coords[1:, :2] += np.random.normal(loc=0.0, scale=scale, size=coords[1:, :2].shape)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def encode_ascii(ascii_string):\n",
    "    \"\"\"\n",
    "    encodes ascii string to array of ints\n",
    "    \"\"\"\n",
    "    return np.array(list(map(lambda x: alpha_to_num[x], ascii_string)) + [0])\n",
    "\n",
    "\n",
    "def denoise(coords):\n",
    "    \"\"\"\n",
    "    smoothing filter to mitigate some artifacts of the data collection\n",
    "    \"\"\"\n",
    "    coords = np.split(coords, np.where(coords[:, 2] == 1)[0] + 1, axis=0)\n",
    "    new_coords = []\n",
    "    for stroke in coords:\n",
    "        if len(stroke) != 0:\n",
    "            x_new = savgol_filter(stroke[:, 0], 7, 3, mode='nearest')\n",
    "            y_new = savgol_filter(stroke[:, 1], 7, 3, mode='nearest')\n",
    "            xy_coords = np.hstack([x_new.reshape(-1, 1), y_new.reshape(-1, 1)])\n",
    "            stroke = np.concatenate([xy_coords, stroke[:, 2].reshape(-1, 1)], axis=1)\n",
    "            new_coords.append(stroke)\n",
    "\n",
    "    coords = np.vstack(new_coords)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def interpolate(coords, factor=2):\n",
    "    \"\"\"\n",
    "    interpolates strokes using cubic spline\n",
    "    \"\"\"\n",
    "    coords = np.split(coords, np.where(coords[:, 2] == 1)[0] + 1, axis=0)\n",
    "    new_coords = []\n",
    "    for stroke in coords:\n",
    "\n",
    "        if len(stroke) == 0:\n",
    "            continue\n",
    "\n",
    "        xy_coords = stroke[:, :2]\n",
    "\n",
    "        if len(stroke) > 3:\n",
    "            f_x = interp1d(np.arange(len(stroke)), stroke[:, 0], kind='cubic')\n",
    "            f_y = interp1d(np.arange(len(stroke)), stroke[:, 1], kind='cubic')\n",
    "\n",
    "            xx = np.linspace(0, len(stroke) - 1, factor*(len(stroke)))\n",
    "            yy = np.linspace(0, len(stroke) - 1, factor*(len(stroke)))\n",
    "\n",
    "            x_new = f_x(xx)\n",
    "            y_new = f_y(yy)\n",
    "\n",
    "            xy_coords = np.hstack([x_new.reshape(-1, 1), y_new.reshape(-1, 1)])\n",
    "\n",
    "        stroke_eos = np.zeros([len(xy_coords), 1])\n",
    "        stroke_eos[-1] = 1.0\n",
    "        stroke = np.concatenate([xy_coords, stroke_eos], axis=1)\n",
    "        new_coords.append(stroke)\n",
    "\n",
    "    coords = np.vstack(new_coords)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def normalize(offsets):\n",
    "    \"\"\"\n",
    "    normalizes strokes to median unit norm\n",
    "    \"\"\"\n",
    "    offsets = np.copy(offsets)\n",
    "    offsets[:, :2] /= np.median(np.linalg.norm(offsets[:, :2], axis=1))\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def coords_to_offsets(coords):\n",
    "    \"\"\"\n",
    "    convert from coordinates to offsets\n",
    "    \"\"\"\n",
    "    offsets = np.concatenate([coords[1:, :2] - coords[:-1, :2], coords[1:, 2:3]], axis=1)\n",
    "    offsets = np.concatenate([np.array([[0, 0, 1]]), offsets], axis=0)\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def offsets_to_coords(offsets):\n",
    "    \"\"\"\n",
    "    convert from offsets to coordinates\n",
    "    \"\"\"\n",
    "    return np.concatenate([np.cumsum(offsets[:, :2], axis=0), offsets[:, 2:3]], axis=1)\n",
    "\n",
    "\n",
    "def draw(\n",
    "        offsets,\n",
    "        ascii_seq=None,\n",
    "        align_strokes=True,\n",
    "        denoise_strokes=True,\n",
    "        interpolation_factor=None,\n",
    "        save_file=None\n",
    "):\n",
    "    strokes = offsets_to_coords(offsets)\n",
    "\n",
    "    if denoise_strokes:\n",
    "        strokes = denoise(strokes)\n",
    "\n",
    "    if interpolation_factor is not None:\n",
    "        strokes = interpolate(strokes, factor=interpolation_factor)\n",
    "\n",
    "    if align_strokes:\n",
    "        strokes[:, :2] = align(strokes[:, :2])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "\n",
    "    stroke = []\n",
    "    for x, y, eos in strokes:\n",
    "        stroke.append((x, y))\n",
    "        if eos == 1:\n",
    "            coords = zip(*stroke)\n",
    "            ax.plot(coords[0], coords[1], 'k')\n",
    "            stroke = []\n",
    "    if stroke:\n",
    "        coords = zip(*stroke)\n",
    "        ax.plot(coords[0], coords[1], 'k')\n",
    "        stroke = []\n",
    "\n",
    "    ax.set_xlim(-50, 600)\n",
    "    ax.set_ylim(-40, 40)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tick_params(\n",
    "        axis='both',\n",
    "        left='off',\n",
    "        top='off',\n",
    "        right='off',\n",
    "        bottom='off',\n",
    "        labelleft='off',\n",
    "        labeltop='off',\n",
    "        labelright='off',\n",
    "        labelbottom='off'\n",
    "    )\n",
    "\n",
    "    if ascii_seq is not None:\n",
    "        if not isinstance(ascii_seq, str):\n",
    "            ascii_seq = ''.join(list(map(chr, ascii_seq)))\n",
    "        plt.title(ascii_seq)\n",
    "\n",
    "    if save_file is not None:\n",
    "        plt.savefig(save_file)\n",
    "        print('saved to {}'.format(save_file))\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "067c4fab-a2a4-4e10-b03c-b2b537c278cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "\n",
    "\n",
    "def _draw(strokes, lines, filename, stroke_colors=None, stroke_widths=None):\n",
    "    stroke_colors = stroke_colors or ['black']*len(lines)\n",
    "    stroke_widths = stroke_widths or [2]*len(lines)\n",
    "\n",
    "    line_height = 60\n",
    "    view_width = 1000\n",
    "    view_height = line_height*(len(strokes) + 1)\n",
    "\n",
    "    dwg = svgwrite.Drawing(filename=filename)\n",
    "    dwg.viewbox(width=view_width, height=view_height)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=(view_width, view_height), fill='white'))\n",
    "\n",
    "    initial_coord = np.array([0, -(3*line_height / 4)])\n",
    "    for offsets, line, color, width in zip(strokes, lines, stroke_colors, stroke_widths):\n",
    "\n",
    "        if not line:\n",
    "            initial_coord[1] -= line_height\n",
    "            continue\n",
    "\n",
    "        offsets[:, :2] *= 1.5\n",
    "        strokes = offsets_to_coords(offsets)\n",
    "        strokes = denoise(strokes)\n",
    "        strokes[:, :2] = align(strokes[:, :2])\n",
    "\n",
    "        strokes[:, 1] *= -1\n",
    "        strokes[:, :2] -= strokes[:, :2].min() + initial_coord\n",
    "        strokes[:, 0] += (view_width - strokes[:, 0].max()) / 2\n",
    "\n",
    "        prev_eos = 1.0\n",
    "        p = \"M{},{} \".format(0, 0)\n",
    "        for x, y, eos in zip(*strokes.T):\n",
    "            p += '{}{},{} '.format('M' if prev_eos == 1.0 else 'L', x, y)\n",
    "            prev_eos = eos\n",
    "        path = svgwrite.path.Path(p)\n",
    "        path = path.stroke(color=color, width=width, linecap='round').fill(\"none\")\n",
    "        dwg.add(path)\n",
    "\n",
    "        initial_coord[1] -= line_height\n",
    "\n",
    "    dwg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bad9f7-1dc3-41a8-88d9-1f35e2433c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  1.0000],\n",
       "        [ 0.1970, -0.2660,  0.0000],\n",
       "        [ 0.1404, -0.1231,  0.0000],\n",
       "        ...,\n",
       "        [-0.1428,  1.1131,  0.0000],\n",
       "        [-0.3103,  0.8447,  1.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "x = data[0][sample_idx]\n",
    "x_len = data[1][sample_idx]\n",
    "c = data[2][sample_idx]\n",
    "c_len = data[3][sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d77623-5cf6-44af-aa59-c1c1042bd39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(612, dtype=torch.int16) tensor(36, dtype=torch.int8)\n",
      "torch.Size([1200, 3]) ['\"', 'I', ' ', \"'\", 'l', 'l', ' ', 't', 'r', 'y', ' ', 't', 'o', ' ', 'r', 'e', 'm', 'e', 'm', 'b', 'e', 'r', '.', ' ', 'S', 'h', 'a', 'l', 'l', ' ', 'w', 'e', ' ', 'g', 'o', '\\x00']\n",
      "\"I 'll try to remember. Shall we go\u0000\n",
      "torch.Size([612, 3])\n",
      "tensor(612, dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "x = data[0][sample_idx]\n",
    "x_len = data[1][sample_idx]\n",
    "c = data[2][sample_idx]\n",
    "c_len = data[3][sample_idx]\n",
    "print(x_len, c_len)\n",
    "print(x.shape, [ALPHABET[i] for i in c[:c_len]])\n",
    "print(    \"\".join([ALPHABET[i] for i in c[:c_len]]))\n",
    "\n",
    "x = x[:x_len]\n",
    "print(x.shape)\n",
    "print(x_len)\n",
    "\n",
    "lines = [\n",
    "    \"\".join([ALPHABET[i] for i in c[:c_len]])\n",
    "]\n",
    "biases = [.75 for i in lines]\n",
    "styles = [9 for i in lines]\n",
    "strokes = x.unsqueeze(0)\n",
    "filename = \"out.svg\"\n",
    "\n",
    "_draw(strokes, lines, filename, stroke_colors=None, stroke_widths=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c448d-da7f-4fa3-8f2f-b98003a6f88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82ecb24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 11034\n",
      "val size 581\n",
      "test size 11615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x        float32\n",
       "x_len      int16\n",
       "c           int8\n",
       "c_len       int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "dr = DataReader(\"processed\")\n",
    "# %%\n",
    "dr.train_df.dtypes()\n",
    "# torch.tensor(dr.train_df['c'])\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5314fe5-54d9-4472-85e4-f54b93285224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgt_mask(size) -> torch.tensor:\n",
    "    # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "    mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "    mask = mask.float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "    mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "\n",
    "    # EX for size=5:\n",
    "    # [[0., -inf, -inf, -inf, -inf],\n",
    "    #  [0.,   0., -inf, -inf, -inf],\n",
    "    #  [0.,   0.,   0., -inf, -inf],\n",
    "    #  [0.,   0.,   0.,   0., -inf],\n",
    "    #  [0.,   0.,   0.,   0.,   0.]]\n",
    "\n",
    "    return mask\n",
    "\n",
    "def create_pad_mask(matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "    # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "    # [False, False, False, True, True, True]\n",
    "    return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14853a63-273b-4679-b17f-1ebc3d01bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 950, 3)\n",
      "(11, 42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_x = None\n",
    "batch_c = None\n",
    "for i in dr.train_batch_generator(11):\n",
    "    batch = i\n",
    "    print(i['x'].shape)\n",
    "    print(i['c'].shape)\n",
    "    batch_x = i['x']\n",
    "    batch_c = i['c']\n",
    "    # print(i['c'])\n",
    "    print()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43fe220b-aaba-4263-b456-e19344a1ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_pad_mask(batch_c, torch.tensor([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b384a4e8-88ba-497a-8278-1f4b5fdd8742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 594\n",
      "1 849\n",
      "2 513\n",
      "3 569\n",
      "4 632\n",
      "5 505\n",
      "6 950\n",
      "7 419\n",
      "8 556\n",
      "9 702\n",
      "10 678\n"
     ]
    }
   ],
   "source": [
    "pad_mask = torch.ones_like(torch.tensor(batch['x']))\n",
    "for i, l in enumerate(batch['x_len']):\n",
    "    print(i, l)\n",
    "    pad_mask[i, l:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f535c57-32b3-415e-a8f5-c3f4fcbd8649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(batch['x']) * pad_mask == torch.tensor(batch['x'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f23f211-385e-4af9-bf63-3b6864478577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6020, -0.0879,  0.4007],\n",
      "         [ 0.8236, -1.1303, -0.4993],\n",
      "         [-0.3771, -0.8300, -0.2342],\n",
      "         [ 0.1727, -1.9924, -0.3265]],\n",
      "\n",
      "        [[-0.3771, -0.8300, -0.2342],\n",
      "         [ 1.5637,  0.5562,  0.6208],\n",
      "         [ 0.8236, -1.1303, -0.4993],\n",
      "         [ 0.9442, -0.6144, -0.9216]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "print(embedding(input))\n",
    "print(embedding(input).shape)\n",
    "\n",
    "\n",
    "# # example with padding_idx\n",
    "# embedding = nn.Embedding(10, 3, padding_idx=0)\n",
    "# input = torch.LongTensor([[0,2,0,5]])\n",
    "# embedding(input)\n",
    "\n",
    "# # example of changing `pad` vector\n",
    "# padding_idx = 0\n",
    "# embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
    "# embedding.weight\n",
    "# with torch.no_grad():\n",
    "#     embedding.weight[padding_idx] = torch.ones(3)\n",
    "# embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db2e9591-39c6-4f8a-90bf-b693904c9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "loss = F.binary_cross_entropy_with_logits(input, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a451e60a-c385-4b1b-afa1-64aa926a1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "823fb6af-9cbf-4a82-accc-3739402e1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4580, -1.0515,  0.7332], requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e5aba61-6984-4533-b1e4-7727f7d330ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "        data_cols = ['x', 'x_len', 'c', 'c_len']\n",
    "        data = [torch.tensor(np.load(os.path.join(data_dir, '{}.npy'.format(i)))) for i in data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ab2e907-64e3-4247-b01f-2ed3ff22584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 32,  1,  ...,  0,  0,  0],\n",
       "        [61, 69, 23,  ...,  0,  0,  0],\n",
       "        [41, 54, 51,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [49, 54, 47,  ...,  0,  0,  0],\n",
       "        [53, 47, 64,  ...,  0,  0,  0],\n",
       "        [49, 61, 59,  ...,  0,  0,  0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
