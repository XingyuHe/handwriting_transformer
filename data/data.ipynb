{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37aebbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# from data_frame import *\n",
    "# from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6fd2ae-0311-4a44-8907-2096547f3d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11615, 1200, 3])\n"
     ]
    }
   ],
   "source": [
    "data_cols = ['x', 'x_len', 'c', 'c_len', 'w_id']\n",
    "data_dir = \"processed\"\n",
    "data = []\n",
    "\n",
    "for col in data_cols:\n",
    "    data.append(\n",
    "        torch.from_numpy(\n",
    "            np.load(os.path.join(data_dir, '{}.npy'.format(col)))\n",
    "        )\n",
    "    )\n",
    "print(data[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e32dfa6-3d80-4402-b685-35c387ccc2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  1.0000],\n",
       "        [ 0.1970, -0.2660,  0.0000],\n",
       "        [ 0.1404, -0.1231,  0.0000],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110cf467-d105-4e6e-87fa-a51849e8f59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ALPHABET = [\n",
    "    '\\x00', ' ', '!', '\"', '#', \"'\", '(', ')', ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';',\n",
    "    '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "    'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "    'y', 'z'\n",
    "]\n",
    "len(ALPHABET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "122becdc-9755-4c60-8323-4720a32122c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Sigmoid()\n",
    "input = torch.randn(2)\n",
    "output = m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24e6360e-cb36-48ea-b545-18ae6934f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 56\n",
      "val size 3\n",
      "test size 59\n"
     ]
    }
   ],
   "source": [
    "DR = WriterDataReader(\"processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54536ea7-23dc-4495-b0ba-17c28106b895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.0096, -0.1607,  0.0000],\n",
      "         [-0.0336, -0.3333,  0.0000],\n",
      "         ...,\n",
      "         [ 0.1535, -0.1487,  0.0000],\n",
      "         [ 0.0959,  0.2974,  0.0000],\n",
      "         [ 0.0168,  0.4556,  1.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.1593,  0.0774,  0.0000],\n",
      "         [-0.2456,  0.0752,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gen = DR.train_batch_generator(2)\n",
    "for d in gen:\n",
    "    print(d['x'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccd6f352-0986-493f-8276-aa645a2c03b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 11034\n",
      "val size 581\n",
      "test size 11615\n",
      "tensor([[[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.0902, -0.0391,  0.0000],\n",
      "         [-0.0090, -0.0661,  0.0000],\n",
      "         ...,\n",
      "         [ 1.0788,  0.6641,  0.0000],\n",
      "         [ 0.8865,  0.3937,  0.0000],\n",
      "         [ 0.5770,  0.1533,  1.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  1.0000],\n",
      "         [-0.1063,  0.0792,  0.0000],\n",
      "         [-0.0667,  0.1001,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "D = DataReader(\"processed\")\n",
    "for d in D.train_batch_generator(2):\n",
    "    print(d['x'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18f20553-7eb5-4da6-9621-de6b17103ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "alphabet = [\n",
    "    '\\x00', ' ', '!', '\"', '#', \"'\", '(', ')', ',', '-', '.',\n",
    "    '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';',\n",
    "    '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K',\n",
    "    'L', 'M', 'N', 'O', 'P', 'R', 'S', 'T', 'U', 'V', 'W', 'Y',\n",
    "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "    'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "    'y', 'z'\n",
    "]\n",
    "alphabet_ord = list(map(ord, alphabet))\n",
    "alpha_to_num = defaultdict(int, list(map(reversed, enumerate(alphabet))))\n",
    "num_to_alpha = dict(enumerate(alphabet_ord))\n",
    "\n",
    "MAX_STROKE_LEN = 1200\n",
    "MAX_CHAR_LEN = 75\n",
    "\n",
    "\n",
    "def align(coords):\n",
    "    \"\"\"\n",
    "    corrects for global slant/offset in handwriting strokes\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    X, Y = coords[:, 0].reshape(-1, 1), coords[:, 1].reshape(-1, 1)\n",
    "    X = np.concatenate([np.ones([X.shape[0], 1]), X], axis=1)\n",
    "    offset, slope = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y).squeeze()\n",
    "    theta = np.arctan(slope)\n",
    "    rotation_matrix = np.array(\n",
    "        [[np.cos(theta), -np.sin(theta)],\n",
    "         [np.sin(theta), np.cos(theta)]]\n",
    "    )\n",
    "    coords[:, :2] = np.dot(coords[:, :2], rotation_matrix) - offset\n",
    "    return coords\n",
    "\n",
    "\n",
    "def skew(coords, degrees):\n",
    "    \"\"\"\n",
    "    skews strokes by given degrees\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    theta = degrees * np.pi/180\n",
    "    A = np.array([[np.cos(-theta), 0], [np.sin(-theta), 1]])\n",
    "    coords[:, :2] = np.dot(coords[:, :2], A)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def stretch(coords, x_factor, y_factor):\n",
    "    \"\"\"\n",
    "    stretches strokes along x and y axis\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    coords[:, :2] *= np.array([x_factor, y_factor])\n",
    "    return coords\n",
    "\n",
    "\n",
    "def add_noise(coords, scale):\n",
    "    \"\"\"\n",
    "    adds gaussian noise to strokes\n",
    "    \"\"\"\n",
    "    coords = np.copy(coords)\n",
    "    coords[1:, :2] += np.random.normal(loc=0.0, scale=scale, size=coords[1:, :2].shape)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def encode_ascii(ascii_string):\n",
    "    \"\"\"\n",
    "    encodes ascii string to array of ints\n",
    "    \"\"\"\n",
    "    return np.array(list(map(lambda x: alpha_to_num[x], ascii_string)) + [0])\n",
    "\n",
    "\n",
    "def denoise(coords):\n",
    "    \"\"\"\n",
    "    smoothing filter to mitigate some artifacts of the data collection\n",
    "    \"\"\"\n",
    "    coords = np.split(coords, np.where(coords[:, 2] == 1)[0] + 1, axis=0)\n",
    "    new_coords = []\n",
    "    for stroke in coords:\n",
    "        if len(stroke) != 0:\n",
    "            x_new = savgol_filter(stroke[:, 0], 7, 3, mode='nearest')\n",
    "            y_new = savgol_filter(stroke[:, 1], 7, 3, mode='nearest')\n",
    "            xy_coords = np.hstack([x_new.reshape(-1, 1), y_new.reshape(-1, 1)])\n",
    "            stroke = np.concatenate([xy_coords, stroke[:, 2].reshape(-1, 1)], axis=1)\n",
    "            new_coords.append(stroke)\n",
    "\n",
    "    coords = np.vstack(new_coords)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def interpolate(coords, factor=2):\n",
    "    \"\"\"\n",
    "    interpolates strokes using cubic spline\n",
    "    \"\"\"\n",
    "    coords = np.split(coords, np.where(coords[:, 2] == 1)[0] + 1, axis=0)\n",
    "    new_coords = []\n",
    "    for stroke in coords:\n",
    "\n",
    "        if len(stroke) == 0:\n",
    "            continue\n",
    "\n",
    "        xy_coords = stroke[:, :2]\n",
    "\n",
    "        if len(stroke) > 3:\n",
    "            f_x = interp1d(np.arange(len(stroke)), stroke[:, 0], kind='cubic')\n",
    "            f_y = interp1d(np.arange(len(stroke)), stroke[:, 1], kind='cubic')\n",
    "\n",
    "            xx = np.linspace(0, len(stroke) - 1, factor*(len(stroke)))\n",
    "            yy = np.linspace(0, len(stroke) - 1, factor*(len(stroke)))\n",
    "\n",
    "            x_new = f_x(xx)\n",
    "            y_new = f_y(yy)\n",
    "\n",
    "            xy_coords = np.hstack([x_new.reshape(-1, 1), y_new.reshape(-1, 1)])\n",
    "\n",
    "        stroke_eos = np.zeros([len(xy_coords), 1])\n",
    "        stroke_eos[-1] = 1.0\n",
    "        stroke = np.concatenate([xy_coords, stroke_eos], axis=1)\n",
    "        new_coords.append(stroke)\n",
    "\n",
    "    coords = np.vstack(new_coords)\n",
    "    return coords\n",
    "\n",
    "\n",
    "def normalize(offsets):\n",
    "    \"\"\"\n",
    "    normalizes strokes to median unit norm\n",
    "    \"\"\"\n",
    "    offsets = np.copy(offsets)\n",
    "    offsets[:, :2] /= np.median(np.linalg.norm(offsets[:, :2], axis=1))\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def coords_to_offsets(coords):\n",
    "    \"\"\"\n",
    "    convert from coordinates to offsets\n",
    "    \"\"\"\n",
    "    offsets = np.concatenate([coords[1:, :2] - coords[:-1, :2], coords[1:, 2:3]], axis=1)\n",
    "    offsets = np.concatenate([np.array([[0, 0, 1]]), offsets], axis=0)\n",
    "    return offsets\n",
    "\n",
    "\n",
    "def offsets_to_coords(offsets):\n",
    "    \"\"\"\n",
    "    convert from offsets to coordinates\n",
    "    \"\"\"\n",
    "    return np.concatenate([np.cumsum(offsets[:, :2], axis=0), offsets[:, 2:3]], axis=1)\n",
    "\n",
    "\n",
    "def draw(\n",
    "        offsets,\n",
    "        ascii_seq=None,\n",
    "        align_strokes=True,\n",
    "        denoise_strokes=True,\n",
    "        interpolation_factor=None,\n",
    "        save_file=None\n",
    "):\n",
    "    strokes = offsets_to_coords(offsets)\n",
    "\n",
    "    if denoise_strokes:\n",
    "        strokes = denoise(strokes)\n",
    "\n",
    "    if interpolation_factor is not None:\n",
    "        strokes = interpolate(strokes, factor=interpolation_factor)\n",
    "\n",
    "    if align_strokes:\n",
    "        strokes[:, :2] = align(strokes[:, :2])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 3))\n",
    "\n",
    "    stroke = []\n",
    "    for x, y, eos in strokes:\n",
    "        stroke.append((x, y))\n",
    "        if eos == 1:\n",
    "            coords = zip(*stroke)\n",
    "            ax.plot(coords[0], coords[1], 'k')\n",
    "            stroke = []\n",
    "    if stroke:\n",
    "        coords = zip(*stroke)\n",
    "        ax.plot(coords[0], coords[1], 'k')\n",
    "        stroke = []\n",
    "\n",
    "    ax.set_xlim(-50, 600)\n",
    "    ax.set_ylim(-40, 40)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    plt.tick_params(\n",
    "        axis='both',\n",
    "        left='off',\n",
    "        top='off',\n",
    "        right='off',\n",
    "        bottom='off',\n",
    "        labelleft='off',\n",
    "        labeltop='off',\n",
    "        labelright='off',\n",
    "        labelbottom='off'\n",
    "    )\n",
    "\n",
    "    if ascii_seq is not None:\n",
    "        if not isinstance(ascii_seq, str):\n",
    "            ascii_seq = ''.join(list(map(chr, ascii_seq)))\n",
    "        plt.title(ascii_seq)\n",
    "\n",
    "    if save_file is not None:\n",
    "        plt.savefig(save_file)\n",
    "        print('saved to {}'.format(save_file))\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "067c4fab-a2a4-4e10-b03c-b2b537c278cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import svgwrite\n",
    "\n",
    "\n",
    "def _draw(strokes, lines, filename, stroke_colors=None, stroke_widths=None):\n",
    "    stroke_colors = stroke_colors or ['black']*len(lines)\n",
    "    stroke_widths = stroke_widths or [2]*len(lines)\n",
    "\n",
    "    line_height = 60\n",
    "    view_width = 1000\n",
    "    view_height = line_height*(len(strokes) + 1)\n",
    "\n",
    "    dwg = svgwrite.Drawing(filename=filename)\n",
    "    dwg.viewbox(width=view_width, height=view_height)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=(view_width, view_height), fill='white'))\n",
    "\n",
    "    initial_coord = np.array([0, -(3*line_height / 4)])\n",
    "    for offsets, line, color, width in zip(strokes, lines, stroke_colors, stroke_widths):\n",
    "\n",
    "        if not line:\n",
    "            initial_coord[1] -= line_height\n",
    "            continue\n",
    "\n",
    "        offsets[:, :2] *= 1.5\n",
    "        strokes = offsets_to_coords(offsets)\n",
    "        strokes = denoise(strokes)\n",
    "        strokes[:, :2] = align(strokes[:, :2])\n",
    "\n",
    "        strokes[:, 1] *= -1\n",
    "        strokes[:, :2] -= strokes[:, :2].min() + initial_coord\n",
    "        strokes[:, 0] += (view_width - strokes[:, 0].max()) / 2\n",
    "\n",
    "        prev_eos = 1.0\n",
    "        p = \"M{},{} \".format(0, 0)\n",
    "        for x, y, eos in zip(*strokes.T):\n",
    "            p += '{}{},{} '.format('M' if prev_eos == 1.0 else 'L', x, y)\n",
    "            prev_eos = eos\n",
    "        path = svgwrite.path.Path(p)\n",
    "        path = path.stroke(color=color, width=width, linecap='round').fill(\"none\")\n",
    "        dwg.add(path)\n",
    "\n",
    "        initial_coord[1] -= line_height\n",
    "\n",
    "    dwg.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6bad9f7-1dc3-41a8-88d9-1f35e2433c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  1.0000],\n",
       "        [ 0.1970, -0.2660,  0.0000],\n",
       "        [ 0.1404, -0.1231,  0.0000],\n",
       "        ...,\n",
       "        [-0.1428,  1.1131,  0.0000],\n",
       "        [-0.3103,  0.8447,  1.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "x = data[0][sample_idx]\n",
    "x_len = data[1][sample_idx]\n",
    "c = data[2][sample_idx]\n",
    "c_len = data[3][sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66d77623-5cf6-44af-aa59-c1c1042bd39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(612, dtype=torch.int16) tensor(36, dtype=torch.int8)\n",
      "torch.Size([1200, 3]) ['\"', 'I', ' ', \"'\", 'l', 'l', ' ', 't', 'r', 'y', ' ', 't', 'o', ' ', 'r', 'e', 'm', 'e', 'm', 'b', 'e', 'r', '.', ' ', 'S', 'h', 'a', 'l', 'l', ' ', 'w', 'e', ' ', 'g', 'o', '\\x00']\n",
      "\"I 'll try to remember. Shall we go\u0000\n",
      "torch.Size([612, 3])\n",
      "tensor(612, dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "x = data[0][sample_idx]\n",
    "x_len = data[1][sample_idx]\n",
    "c = data[2][sample_idx]\n",
    "c_len = data[3][sample_idx]\n",
    "print(x_len, c_len)\n",
    "print(x.shape, [ALPHABET[i] for i in c[:c_len]])\n",
    "print(    \"\".join([ALPHABET[i] for i in c[:c_len]]))\n",
    "\n",
    "x = x[:x_len]\n",
    "print(x.shape)\n",
    "print(x_len)\n",
    "\n",
    "lines = [\n",
    "    \"\".join([ALPHABET[i] for i in c[:c_len]])\n",
    "]\n",
    "biases = [.75 for i in lines]\n",
    "styles = [9 for i in lines]\n",
    "strokes = x.unsqueeze(0)\n",
    "filename = \"out.svg\"\n",
    "\n",
    "_draw(strokes, lines, filename, stroke_colors=None, stroke_widths=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48c448d-da7f-4fa3-8f2f-b98003a6f88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "82ecb24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size 11034\n",
      "val size 581\n",
      "test size 11615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "x        float32\n",
       "x_len      int16\n",
       "c           int8\n",
       "c_len       int8\n",
       "dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "dr = DataReader(\"processed\")\n",
    "# %%\n",
    "dr.train_df.dtypes()\n",
    "# torch.tensor(dr.train_df['c'])\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5314fe5-54d9-4472-85e4-f54b93285224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tgt_mask(size) -> torch.tensor:\n",
    "    # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "    mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "    mask = mask.float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "    mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "\n",
    "    # EX for size=5:\n",
    "    # [[0., -inf, -inf, -inf, -inf],\n",
    "    #  [0.,   0., -inf, -inf, -inf],\n",
    "    #  [0.,   0.,   0., -inf, -inf],\n",
    "    #  [0.,   0.,   0.,   0., -inf],\n",
    "    #  [0.,   0.,   0.,   0.,   0.]]\n",
    "\n",
    "    return mask\n",
    "\n",
    "def create_pad_mask(matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "    # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "    # [False, False, False, True, True, True]\n",
    "    return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14853a63-273b-4679-b17f-1ebc3d01bbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 950, 3)\n",
      "(11, 42)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_x = None\n",
    "batch_c = None\n",
    "for i in dr.train_batch_generator(11):\n",
    "    batch = i\n",
    "    print(i['x'].shape)\n",
    "    print(i['c'].shape)\n",
    "    batch_x = i['x']\n",
    "    batch_c = i['c']\n",
    "    # print(i['c'])\n",
    "    print()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43fe220b-aaba-4263-b456-e19344a1ad35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_pad_mask(batch_c, torch.tensor([0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b384a4e8-88ba-497a-8278-1f4b5fdd8742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 594\n",
      "1 849\n",
      "2 513\n",
      "3 569\n",
      "4 632\n",
      "5 505\n",
      "6 950\n",
      "7 419\n",
      "8 556\n",
      "9 702\n",
      "10 678\n"
     ]
    }
   ],
   "source": [
    "pad_mask = torch.ones_like(torch.tensor(batch['x']))\n",
    "for i, l in enumerate(batch['x_len']):\n",
    "    print(i, l)\n",
    "    pad_mask[i, l:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f535c57-32b3-415e-a8f5-c3f4fcbd8649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(batch['x']) * pad_mask == torch.tensor(batch['x'])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f23f211-385e-4af9-bf63-3b6864478577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6020, -0.0879,  0.4007],\n",
      "         [ 0.8236, -1.1303, -0.4993],\n",
      "         [-0.3771, -0.8300, -0.2342],\n",
      "         [ 0.1727, -1.9924, -0.3265]],\n",
      "\n",
      "        [[-0.3771, -0.8300, -0.2342],\n",
      "         [ 1.5637,  0.5562,  0.6208],\n",
      "         [ 0.8236, -1.1303, -0.4993],\n",
      "         [ 0.9442, -0.6144, -0.9216]]], grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([2, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "# an Embedding module containing 10 tensors of size 3\n",
    "embedding = nn.Embedding(10, 3)\n",
    "# a batch of 2 samples of 4 indices each\n",
    "input = torch.LongTensor([[1,2,4,5],[4,3,2,9]])\n",
    "print(embedding(input))\n",
    "print(embedding(input).shape)\n",
    "\n",
    "\n",
    "# # example with padding_idx\n",
    "# embedding = nn.Embedding(10, 3, padding_idx=0)\n",
    "# input = torch.LongTensor([[0,2,0,5]])\n",
    "# embedding(input)\n",
    "\n",
    "# # example of changing `pad` vector\n",
    "# padding_idx = 0\n",
    "# embedding = nn.Embedding(3, 3, padding_idx=padding_idx)\n",
    "# embedding.weight\n",
    "# with torch.no_grad():\n",
    "#     embedding.weight[padding_idx] = torch.ones(3)\n",
    "# embedding.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "db2e9591-39c6-4f8a-90bf-b693904c9baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "loss = F.binary_cross_entropy_with_logits(input, target)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a451e60a-c385-4b1b-afa1-64aa926a1e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "823fb6af-9cbf-4a82-accc-3739402e1efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4580, -1.0515,  0.7332], requires_grad=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4e5aba61-6984-4533-b1e4-7727f7d330ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "        data_cols = ['x', 'x_len', 'c', 'c_len']\n",
    "        data = [torch.tensor(np.load(os.path.join(data_dir, '{}.npy'.format(i)))) for i in data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ab2e907-64e3-4247-b01f-2ed3ff22584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3, 32,  1,  ...,  0,  0,  0],\n",
       "        [61, 69, 23,  ...,  0,  0,  0],\n",
       "        [41, 54, 51,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [49, 54, 47,  ...,  0,  0,  0],\n",
       "        [53, 47, 64,  ...,  0,  0,  0],\n",
       "        [49, 61, 59,  ...,  0,  0,  0]], dtype=torch.int8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
